{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":2371.650802,"end_time":"2023-01-06T22:48:57.404827","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-01-06T22:09:25.754025","version":"2.3.4"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow import keras \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nimport tensorflow.keras.optimizers\nimport tensorflow as tf\nfrom tensorflow.keras.layers import BatchNormalization\nimport os\nfrom tensorflow.keras.regularizers import l2\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imread, imshow, imsave\nimport cv2\nimport numpy as np\nimport tensorflow\nfrom sklearn.metrics import plot_confusion_matrix# This Python 3 environment comes with many helpful analytics libraries installed","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":8.72652,"end_time":"2023-01-06T22:09:44.276531","exception":false,"start_time":"2023-01-06T22:09:35.550011","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-08T15:51:39.498365Z","iopub.execute_input":"2023-01-08T15:51:39.498941Z","iopub.status.idle":"2023-01-08T15:51:46.969332Z","shell.execute_reply.started":"2023-01-08T15:51:39.498826Z","shell.execute_reply":"2023-01-08T15:51:46.968391Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def load(file_path):\n    image = imread(file_path)\n    return image\ndef display(image,title=\"Image\"):\n    plt.figure(figsize=[10,10])\n    channels=len(image.shape)\n    if channels<3:\n        plt.imshow(image,cmap='Greys_r');\n    else:\n        plt.imshow(image);      \n    plt.title(title);plt.axis(\"off\"); \n    \ndef check_label(file_path):\n    if os.path.getsize(file_path) == 0:\n        return 0\n    else :\n        return 1\ndef load_data(directory):\n    my_counter_0=0\n    my_counter_1=0\n    sequence=[\"x/train\",\"x/test\",\"x/valid\"]\n    train_data=[]\n    test_data=[]\n    valid_data=[]\n    \n    valid_labels=[]\n    test_labels=[]    \n    train_labels=[]\n    for x in sequence:\n        directory_search=directory+x[1:]+'/images'\n        for filename in os.listdir(directory_search):\n            f = os.path.join(directory_search, filename)\n            if os.path.isfile(f):\n                my_image=load(f)\n                resized = cv2.resize(my_image,(299,299), interpolation = cv2.INTER_AREA)\n                if x == 'x/train' :\n                    train_data.append(resized)\n                elif x == 'x/test' :\n                    test_data.append(resized)\n                else:\n                    valid_data.append(resized)\n    \n        directory_search=directory+x[1:]+'/labels'\n        for filename in os.listdir(directory_search):\n            f = os.path.join(directory_search, filename)\n            if os.path.isfile(f):\n                label=check_label(f)\n                if label==0:\n                    my_counter_0+=1\n                elif label==1:\n                    my_counter_1+=1\n                if x == 'x/train' :\n                    train_labels.append(label)\n                elif x == 'x/test' :\n                    test_labels.append(label)\n                else:\n                    valid_labels.append(label)\n    print(\"Defected Pictures : \",my_counter_1)\n    print(\"Non-Defected Pictures : \",my_counter_0)\n\n    return train_data,test_data,valid_data,train_labels,test_labels,valid_labels","metadata":{"papermill":{"duration":0.025751,"end_time":"2023-01-06T22:09:44.305781","exception":false,"start_time":"2023-01-06T22:09:44.280030","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-08T15:51:46.971241Z","iopub.execute_input":"2023-01-08T15:51:46.972127Z","iopub.status.idle":"2023-01-08T15:51:46.987138Z","shell.execute_reply.started":"2023-01-08T15:51:46.972090Z","shell.execute_reply":"2023-01-08T15:51:46.985624Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_data,test_data,valid_data,train_labels,test_labels,valid_labels=load_data(\"/kaggle/input/dataset-final/Defect_Detection_FinalVersion\")\nnp_train_data=np.array(train_data)\nnp_train_data = np_train_data.reshape((np_train_data.shape[0], 299,299, 3))\nnp_train_data = np_train_data.astype(\"float32\") / 255.0\nnp_train_labels = np.asarray(train_labels).astype('float32').reshape((-1,1))\n\nnp_test_data=np.array(test_data)\nnp_test_data = np_test_data.reshape((np_test_data.shape[0], 299,299, 3))\nnp_test_data = np_test_data.astype(\"float32\") / 255.0\nnp_test_labels = np.asarray(test_labels).astype('float32').reshape((-1,1))\n\nnp_valid_data=np.array(valid_data)\nnp_valid_data = np_valid_data.reshape((np_valid_data.shape[0], 299,299, 3))\nnp_valid_data = np_valid_data.astype(\"float32\") / 255.0\nnp_valid_labels = np.asarray(valid_labels).astype('float32').reshape((-1,1))","metadata":{"papermill":{"duration":13.549156,"end_time":"2023-01-06T22:09:57.858132","exception":false,"start_time":"2023-01-06T22:09:44.308976","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-08T15:51:46.989893Z","iopub.execute_input":"2023-01-08T15:51:46.991052Z","iopub.status.idle":"2023-01-08T15:52:11.865340Z","shell.execute_reply.started":"2023-01-08T15:51:46.990914Z","shell.execute_reply":"2023-01-08T15:52:11.863965Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Defected Pictures :  993\nNon-Defected Pictures :  1109\n","output_type":"stream"}]},{"cell_type":"code","source":"class InceptionResNetV2:    \n\n    def build(imgRows, imgCols,numChannels,numClasses):\n        incpet = Sequential()\n        inceptionresnetv2=tf.keras.applications.InceptionResNetV2(include_top=True,weights=\"imagenet\",input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation=\"softmax\")\n        for each_layer in inceptionresnetv2.layers:\n                each_layer.trainable=False\n        incpet.add(inceptionresnetv2)\n        incpet.add(Dense(1,activation='sigmoid'))\n        return incpet","metadata":{"papermill":{"duration":0.017445,"end_time":"2023-01-06T22:09:57.878877","exception":false,"start_time":"2023-01-06T22:09:57.861432","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-08T15:52:11.867507Z","iopub.execute_input":"2023-01-08T15:52:11.867873Z","iopub.status.idle":"2023-01-08T15:52:11.875637Z","shell.execute_reply.started":"2023-01-08T15:52:11.867839Z","shell.execute_reply":"2023-01-08T15:52:11.874279Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model = InceptionResNetV2.build(numChannels=3, imgRows=640, imgCols=640,numClasses=2)\nopt = keras.optimizers.Adam(learning_rate=0.02)\nmodel.compile(loss=\"binary_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\nmodel.fit(np_train_data, np_train_labels, batch_size=64, epochs=40,verbose=1,validation_data=(np_valid_data, np_valid_labels))","metadata":{"papermill":{"duration":2257.225508,"end_time":"2023-01-06T22:47:35.107547","exception":false,"start_time":"2023-01-06T22:09:57.882039","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-08T15:52:11.877077Z","iopub.execute_input":"2023-01-08T15:52:11.877454Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"2023-01-08 15:52:11.918573: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n225214464/225209952 [==============================] - 10s 0us/step\n225222656/225209952 [==============================] - 10s 0us/step\n","output_type":"stream"},{"name":"stderr","text":"2023-01-08 15:52:31.423476: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/40\n29/29 [==============================] - 439s 15s/step - loss: 0.6921 - accuracy: 0.5351 - val_loss: 0.7111 - val_accuracy: 0.3731\nEpoch 2/40\n29/29 [==============================] - 427s 15s/step - loss: 0.6887 - accuracy: 0.5362 - val_loss: 0.7087 - val_accuracy: 0.3806\nEpoch 3/40\n29/29 [==============================] - 428s 15s/step - loss: 0.6872 - accuracy: 0.5378 - val_loss: 0.7087 - val_accuracy: 0.4478\nEpoch 4/40\n29/29 [==============================] - 425s 15s/step - loss: 0.6862 - accuracy: 0.5482 - val_loss: 0.7026 - val_accuracy: 0.5075\nEpoch 5/40\n29/29 [==============================] - 422s 15s/step - loss: 0.6845 - accuracy: 0.5285 - val_loss: 0.7055 - val_accuracy: 0.4776\nEpoch 6/40\n29/29 [==============================] - 420s 15s/step - loss: 0.6832 - accuracy: 0.5389 - val_loss: 0.7083 - val_accuracy: 0.4701\nEpoch 7/40\n29/29 [==============================] - 420s 15s/step - loss: 0.6824 - accuracy: 0.5417 - val_loss: 0.7039 - val_accuracy: 0.5224\nEpoch 8/40\n29/29 [==============================] - 420s 15s/step - loss: 0.6818 - accuracy: 0.5482 - val_loss: 0.7099 - val_accuracy: 0.4701\nEpoch 9/40\n29/29 [==============================] - 421s 15s/step - loss: 0.6808 - accuracy: 0.5356 - val_loss: 0.7090 - val_accuracy: 0.4851\nEpoch 10/40\n29/29 [==============================] - 426s 15s/step - loss: 0.6802 - accuracy: 0.5400 - val_loss: 0.7077 - val_accuracy: 0.5149\nEpoch 11/40\n29/29 [==============================] - 429s 15s/step - loss: 0.6795 - accuracy: 0.5411 - val_loss: 0.7068 - val_accuracy: 0.5149\nEpoch 12/40\n29/29 [==============================] - 423s 15s/step - loss: 0.6786 - accuracy: 0.5400 - val_loss: 0.7097 - val_accuracy: 0.5075\nEpoch 13/40\n29/29 [==============================] - 421s 15s/step - loss: 0.6784 - accuracy: 0.5576 - val_loss: 0.7098 - val_accuracy: 0.4925\nEpoch 14/40\n29/29 [==============================] - 422s 15s/step - loss: 0.6782 - accuracy: 0.5455 - val_loss: 0.7190 - val_accuracy: 0.4403\nEpoch 15/40\n29/29 [==============================] - 420s 14s/step - loss: 0.6771 - accuracy: 0.5559 - val_loss: 0.7109 - val_accuracy: 0.5075\nEpoch 16/40\n29/29 [==============================] - 423s 15s/step - loss: 0.6768 - accuracy: 0.5493 - val_loss: 0.7117 - val_accuracy: 0.5000\nEpoch 17/40\n29/29 [==============================] - 420s 15s/step - loss: 0.6759 - accuracy: 0.5461 - val_loss: 0.7116 - val_accuracy: 0.5075\nEpoch 18/40\n29/29 [==============================] - 422s 15s/step - loss: 0.6752 - accuracy: 0.5576 - val_loss: 0.7112 - val_accuracy: 0.5075\nEpoch 19/40\n29/29 [==============================] - 425s 15s/step - loss: 0.6751 - accuracy: 0.5477 - val_loss: 0.7135 - val_accuracy: 0.5075\nEpoch 20/40\n29/29 [==============================] - 423s 15s/step - loss: 0.6747 - accuracy: 0.5598 - val_loss: 0.7116 - val_accuracy: 0.5000\nEpoch 21/40\n29/29 [==============================] - 420s 15s/step - loss: 0.6748 - accuracy: 0.5455 - val_loss: 0.7205 - val_accuracy: 0.4179\nEpoch 22/40\n 3/29 [==>...........................] - ETA: 5:56 - loss: 0.6696 - accuracy: 0.5312","output_type":"stream"}]},{"cell_type":"code","source":"scores = model.evaluate(np_test_data, np_test_labels, verbose=0)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\nmodel.save('Conv_NetTinny')","metadata":{"papermill":{"duration":79.467711,"end_time":"2023-01-06T22:48:54.610494","exception":false,"start_time":"2023-01-06T22:47:35.142783","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}