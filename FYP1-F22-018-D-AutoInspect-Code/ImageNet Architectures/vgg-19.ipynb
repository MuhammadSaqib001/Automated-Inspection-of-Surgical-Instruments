{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":2371.650802,"end_time":"2023-01-06T22:48:57.404827","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-01-06T22:09:25.754025","version":"2.3.4"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow import keras \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nimport tensorflow.keras.optimizers\nimport tensorflow as tf\nfrom tensorflow.keras.layers import BatchNormalization\nimport os\nfrom tensorflow.keras.regularizers import l2\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imread, imshow, imsave\nimport cv2\nimport numpy as np\nimport tensorflow\nfrom sklearn.metrics import plot_confusion_matrix# This Python 3 environment comes with many helpful analytics libraries installed","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":8.72652,"end_time":"2023-01-06T22:09:44.276531","exception":false,"start_time":"2023-01-06T22:09:35.550011","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-08T15:52:36.315283Z","iopub.execute_input":"2023-01-08T15:52:36.315775Z","iopub.status.idle":"2023-01-08T15:52:43.283057Z","shell.execute_reply.started":"2023-01-08T15:52:36.315676Z","shell.execute_reply":"2023-01-08T15:52:43.281809Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def load(file_path):\n    image = imread(file_path)\n    return image\ndef display(image,title=\"Image\"):\n    plt.figure(figsize=[10,10])\n    channels=len(image.shape)\n    if channels<3:\n        plt.imshow(image,cmap='Greys_r');\n    else:\n        plt.imshow(image);      \n    plt.title(title);plt.axis(\"off\"); \n    \ndef check_label(file_path):\n    if os.path.getsize(file_path) == 0:\n        return 0\n    else :\n        return 1\ndef load_data(directory):\n    my_counter_0=0\n    my_counter_1=0\n    sequence=[\"x/train\",\"x/test\",\"x/valid\"]\n    train_data=[]\n    test_data=[]\n    valid_data=[]\n    \n    valid_labels=[]\n    test_labels=[]    \n    train_labels=[]\n    for x in sequence:\n        directory_search=directory+x[1:]+'/images'\n        for filename in os.listdir(directory_search):\n            f = os.path.join(directory_search, filename)\n            if os.path.isfile(f):\n                my_image=load(f)\n                resized = cv2.resize(my_image,(240,240), interpolation = cv2.INTER_AREA)\n                if x == 'x/train' :\n                    train_data.append(resized)\n                elif x == 'x/test' :\n                    test_data.append(resized)\n                else:\n                    valid_data.append(resized)\n    \n        directory_search=directory+x[1:]+'/labels'\n        for filename in os.listdir(directory_search):\n            f = os.path.join(directory_search, filename)\n            if os.path.isfile(f):\n                label=check_label(f)\n                if label==0:\n                    my_counter_0+=1\n                elif label==1:\n                    my_counter_1+=1\n                if x == 'x/train' :\n                    train_labels.append(label)\n                elif x == 'x/test' :\n                    test_labels.append(label)\n                else:\n                    valid_labels.append(label)\n    print(\"Defected Pictures : \",my_counter_1)\n    print(\"Non-Defected Pictures : \",my_counter_0)\n\n    return train_data,test_data,valid_data,train_labels,test_labels,valid_labels","metadata":{"papermill":{"duration":0.025751,"end_time":"2023-01-06T22:09:44.305781","exception":false,"start_time":"2023-01-06T22:09:44.280030","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-08T15:52:43.284956Z","iopub.execute_input":"2023-01-08T15:52:43.285943Z","iopub.status.idle":"2023-01-08T15:52:43.302035Z","shell.execute_reply.started":"2023-01-08T15:52:43.285905Z","shell.execute_reply":"2023-01-08T15:52:43.300495Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_data,test_data,valid_data,train_labels,test_labels,valid_labels=load_data(\"/kaggle/input/dataset-final/Defect_Detection_FinalVersion\")\nnp_train_data=np.array(train_data)\nnp_train_data = np_train_data.reshape((np_train_data.shape[0], 240,240, 3))\nnp_train_data = np_train_data.astype(\"float32\") / 255.0\nnp_train_labels = np.asarray(train_labels).astype('float32').reshape((-1,1))\n\nnp_test_data=np.array(test_data)\nnp_test_data = np_test_data.reshape((np_test_data.shape[0], 240,240, 3))\nnp_test_data = np_test_data.astype(\"float32\") / 255.0\nnp_test_labels = np.asarray(test_labels).astype('float32').reshape((-1,1))\n\nnp_valid_data=np.array(valid_data)\nnp_valid_data = np_valid_data.reshape((np_valid_data.shape[0], 240,240, 3))\nnp_valid_data = np_valid_data.astype(\"float32\") / 255.0\nnp_valid_labels = np.asarray(valid_labels).astype('float32').reshape((-1,1))","metadata":{"papermill":{"duration":13.549156,"end_time":"2023-01-06T22:09:57.858132","exception":false,"start_time":"2023-01-06T22:09:44.308976","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-08T15:52:43.303962Z","iopub.execute_input":"2023-01-08T15:52:43.304885Z","iopub.status.idle":"2023-01-08T15:53:01.978536Z","shell.execute_reply.started":"2023-01-08T15:52:43.304835Z","shell.execute_reply":"2023-01-08T15:53:01.977492Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Defected Pictures :  993\nNon-Defected Pictures :  1109\n","output_type":"stream"}]},{"cell_type":"code","source":"class VGG_19:    \n\n    def build(imgRows, imgCols,numChannels,numClasses):\n        vgg = Sequential()\n        pretrained_vgg= tf.keras.applications.VGG19(include_top=False,input_shape=(240,240,3),pooling='avg',classes=2,weights='imagenet',classifier_activation=\"relu\")\n        for each_layer in pretrained_vgg.layers:\n                each_layer.trainable=False\n\n        vgg.add(pretrained_vgg)\n        vgg.add(Dense(512, activation='relu'))\n        vgg.add(Dense(256, activation='relu'))\n        vgg.add(Dense(1,activation='relu'))\n   \n        return vgg","metadata":{"papermill":{"duration":0.017445,"end_time":"2023-01-06T22:09:57.878877","exception":false,"start_time":"2023-01-06T22:09:57.861432","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-08T15:53:01.981467Z","iopub.execute_input":"2023-01-08T15:53:01.981954Z","iopub.status.idle":"2023-01-08T15:53:01.989388Z","shell.execute_reply.started":"2023-01-08T15:53:01.981912Z","shell.execute_reply":"2023-01-08T15:53:01.988285Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model = VGG_19.build(numChannels=3, imgRows=640, imgCols=640,numClasses=2)\nopt = keras.optimizers.Adam(learning_rate=0.02)\nmodel.compile(loss=\"binary_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\nmodel.fit(np_train_data, np_train_labels, batch_size=64, epochs=40,verbose=1,validation_data=(np_valid_data, np_valid_labels))","metadata":{"papermill":{"duration":2257.225508,"end_time":"2023-01-06T22:47:35.107547","exception":false,"start_time":"2023-01-06T22:09:57.882039","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-08T15:53:01.991063Z","iopub.execute_input":"2023-01-08T15:53:01.991649Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"2023-01-08 15:53:02.033684: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n80142336/80134624 [==============================] - 0s 0us/step\n80150528/80134624 [==============================] - 0s 0us/step\n","output_type":"stream"},{"name":"stderr","text":"2023-01-08 15:53:04.623503: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/40\n29/29 [==============================] - 695s 24s/step - loss: 7.9139 - accuracy: 0.4682 - val_loss: 5.6900 - val_accuracy: 0.6269\nEpoch 2/40\n29/29 [==============================] - 697s 24s/step - loss: 8.1764 - accuracy: 0.4638 - val_loss: 5.6900 - val_accuracy: 0.6269\nEpoch 3/40\n29/29 [==============================] - 697s 24s/step - loss: 8.1764 - accuracy: 0.4638 - val_loss: 5.6900 - val_accuracy: 0.6269\nEpoch 4/40\n29/29 [==============================] - 696s 24s/step - loss: 8.1764 - accuracy: 0.4638 - val_loss: 5.6900 - val_accuracy: 0.6269\nEpoch 5/40\n29/29 [==============================] - 698s 24s/step - loss: 8.1764 - accuracy: 0.4638 - val_loss: 5.6900 - val_accuracy: 0.6269\nEpoch 6/40\n29/29 [==============================] - 698s 24s/step - loss: 8.1764 - accuracy: 0.4638 - val_loss: 5.6900 - val_accuracy: 0.6269\nEpoch 7/40\n29/29 [==============================] - 709s 25s/step - loss: 8.1764 - accuracy: 0.4638 - val_loss: 5.6900 - val_accuracy: 0.6269\nEpoch 8/40\n29/29 [==============================] - 701s 24s/step - loss: 8.1764 - accuracy: 0.4638 - val_loss: 5.6900 - val_accuracy: 0.6269\nEpoch 9/40\n29/29 [==============================] - 701s 24s/step - loss: 8.1764 - accuracy: 0.4638 - val_loss: 5.6900 - val_accuracy: 0.6269\nEpoch 10/40\n29/29 [==============================] - 698s 24s/step - loss: 8.1764 - accuracy: 0.4638 - val_loss: 5.6900 - val_accuracy: 0.6269\nEpoch 11/40\n29/29 [==============================] - 697s 24s/step - loss: 8.1764 - accuracy: 0.4638 - val_loss: 5.6900 - val_accuracy: 0.6269\nEpoch 12/40\n29/29 [==============================] - 700s 24s/step - loss: 8.1764 - accuracy: 0.4638 - val_loss: 5.6900 - val_accuracy: 0.6269\nEpoch 13/40\n22/29 [=====================>........] - ETA: 2:39 - loss: 8.2636 - accuracy: 0.4581","output_type":"stream"}]},{"cell_type":"code","source":"scores = model.evaluate(np_test_data, np_test_labels, verbose=0)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\nmodel.save('VGG_19')","metadata":{"papermill":{"duration":79.467711,"end_time":"2023-01-06T22:48:54.610494","exception":false,"start_time":"2023-01-06T22:47:35.142783","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}