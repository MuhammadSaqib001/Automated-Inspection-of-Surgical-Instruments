{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade 'git+https://github.com/paulgavrikov/visualkeras'\nfrom tensorflow import keras \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nimport tensorflow.keras.optimizers\nimport tensorflow as tf\nfrom tensorflow.keras.layers import BatchNormalization\nimport os\nfrom tensorflow.keras.regularizers import l2\nimport visualkeras\nfrom PIL import ImageFont\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imread, imshow, imsave\nimport cv2\nimport numpy as np\nimport tensorflow\nfrom sklearn.metrics import plot_confusion_matrix# This Python 3 environment comes with many helpful analytics libraries installed","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-07T13:18:14.575691Z","iopub.execute_input":"2023-01-07T13:18:14.576228Z","iopub.status.idle":"2023-01-07T13:18:28.880555Z","shell.execute_reply.started":"2023-01-07T13:18:14.576183Z","shell.execute_reply":"2023-01-07T13:18:28.878651Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/paulgavrikov/visualkeras\n  Cloning https://github.com/paulgavrikov/visualkeras to /tmp/pip-req-build-89z3uol7\n  Running command git clone --filter=blob:none --quiet https://github.com/paulgavrikov/visualkeras /tmp/pip-req-build-89z3uol7\n  Resolved https://github.com/paulgavrikov/visualkeras to commit d7111d3471173c0b16853a6ce5e4cc645498380a\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from visualkeras==0.0.2) (9.1.1)\nRequirement already satisfied: numpy>=1.18.1 in /opt/conda/lib/python3.7/site-packages (from visualkeras==0.0.2) (1.21.6)\nRequirement already satisfied: aggdraw>=1.3.11 in /opt/conda/lib/python3.7/site-packages (from visualkeras==0.0.2) (1.3.15)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"def load(file_path):\n    image = imread(file_path)\n    return image\ndef display(image,title=\"Image\"):\n    plt.figure(figsize=[10,10])\n    channels=len(image.shape)\n    if channels<3:\n        plt.imshow(image,cmap='Greys_r');\n    else:\n        plt.imshow(image);      \n    plt.title(title);plt.axis(\"off\"); \n    \ndef check_label(file_path):\n    if os.path.getsize(file_path) == 0:\n        return 0\n    else :\n        return 1\ndef load_data(directory):\n    my_counter_0=0\n    my_counter_1=0\n    sequence=[\"x/train\",\"x/test\",\"x/valid\"]\n    train_data=[]\n    test_data=[]\n    valid_data=[]\n    \n    valid_labels=[]\n    test_labels=[]    \n    train_labels=[]\n    for x in sequence:\n        directory_search=directory+x[1:]+'/images'\n        for filename in os.listdir(directory_search):\n            f = os.path.join(directory_search, filename)\n            if os.path.isfile(f):\n                my_image=load(f)\n                if len(my_image.shape)==1:\n                    my_image = cv2.cvtColor(my_image, cv2.COLOR_GRAY2RGB) \n                \n                resized = cv2.resize(my_image,(640,640), interpolation = cv2.INTER_AREA)\n                if x == 'x/train' :\n                    train_data.append(resized)\n                elif x == 'x/test' :\n                    test_data.append(resized)\n                else:\n                    valid_data.append(resized)\n    \n        directory_search=directory+x[1:]+'/labels'\n        for filename in os.listdir(directory_search):\n            f = os.path.join(directory_search, filename)\n            if os.path.isfile(f):\n                label=check_label(f)\n                if label==0:\n                    my_counter_0+=1\n                elif label==1:\n                    my_counter_1+=1\n                if x == 'x/train' :\n                    train_labels.append(label)\n                elif x == 'x/test' :\n                    test_labels.append(label)\n                else:\n                    valid_labels.append(label)\n    print(\"Defected Pictures : \",my_counter_1)\n    print(\"Non-Defected Pictures : \",my_counter_0)\n\n    return train_data,test_data,valid_data,train_labels,test_labels,valid_labels","metadata":{"execution":{"iopub.status.busy":"2023-01-06T18:26:28.934852Z","iopub.execute_input":"2023-01-06T18:26:28.935937Z","iopub.status.idle":"2023-01-06T18:26:28.952397Z","shell.execute_reply.started":"2023-01-06T18:26:28.935885Z","shell.execute_reply":"2023-01-06T18:26:28.951397Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_data,test_data,valid_data,train_labels,test_labels,valid_labels=load_data(\"/kaggle/input/finaldataset-autoinspect/\")\nnp_train_data=np.array(train_data)\nnp_train_data = np_train_data.reshape((np_train_data.shape[0], 640,640, 3))\nnp_train_data = np_train_data.astype(\"float32\") / 255.0\nnp_train_labels = np.asarray(train_labels).astype('float32').reshape((-1,1))\n\nnp_test_data=np.array(test_data)\nnp_test_data = np_test_data.reshape((np_test_data.shape[0], 640,640, 3))\nnp_test_data = np_test_data.astype(\"float32\") / 255.0\nnp_test_labels = np.asarray(test_labels).astype('float32').reshape((-1,1))\n\nnp_valid_data=np.array(valid_data)\nnp_valid_data = np_valid_data.reshape((np_valid_data.shape[0], 640,640, 3))\nnp_valid_data = np_valid_data.astype(\"float32\") / 255.0\nnp_valid_labels = np.asarray(valid_labels).astype('float32').reshape((-1,1))","metadata":{"execution":{"iopub.status.busy":"2023-01-06T18:26:28.953883Z","iopub.execute_input":"2023-01-06T18:26:28.955114Z","iopub.status.idle":"2023-01-06T18:26:48.981784Z","shell.execute_reply.started":"2023-01-06T18:26:28.955068Z","shell.execute_reply":"2023-01-06T18:26:48.980941Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Defected Pictures :  381\nNon-Defected Pictures :  397\n","output_type":"stream"}]},{"cell_type":"code","source":"class AutoNet:    \n\n    def build(imgRows, imgCols,numChannels,numClasses):\n        # initialize the model\n        model = Sequential()\n        inputShape = (imgRows, imgCols, numChannels)\n        \n        model.add(Conv2D(32, 11, padding=\"same\",input_shape=inputShape))\n        model.add(Activation(\"relu\"))\n\n\n        model.add(Conv2D(64, 7, padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        \n        model.add(Conv2D(128, 5, padding=\"same\"))\n        model.add(Activation(\"relu\"))\n\n\n        \n        model.add(Conv2D(32, 3, padding=\"same\"))\n        model.add(Activation(\"relu\"))\n\n        model.add(Conv2D(16, 3, padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(keras.layers.MaxPooling2D(pool_size=(2, 2))) \n        model.add(BatchNormalization())\n\n        model.add(Flatten())\n        model.add(Activation(\"relu\"))\n\n        model.add(Dense(64))\n        model.add(Activation(\"relu\"))\n        \n        model.add(Dense(numClasses-1))\n        model.add(Activation(\"sigmoid\"))\n        return model","metadata":{"execution":{"iopub.status.busy":"2023-01-07T13:21:35.929887Z","iopub.execute_input":"2023-01-07T13:21:35.930969Z","iopub.status.idle":"2023-01-07T13:21:35.943451Z","shell.execute_reply.started":"2023-01-07T13:21:35.930914Z","shell.execute_reply":"2023-01-07T13:21:35.942139Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model = AutoNet.build(numChannels=3, imgRows=640, imgCols=640,numClasses=2)\nmodel.summary()\n# font = ImageFont.truetype(\"arial.ttf\", 32)  \nvisualkeras.layered_view(model, legend=True)  # font is optional!\nvisualkeras.layered_view(model,legend=True, to_file='output.png').show() # write and show","metadata":{"execution":{"iopub.status.busy":"2023-01-07T13:21:40.668127Z","iopub.execute_input":"2023-01-07T13:21:40.668590Z","iopub.status.idle":"2023-01-07T13:21:42.859188Z","shell.execute_reply.started":"2023-01-07T13:21:40.668552Z","shell.execute_reply":"2023-01-07T13:21:42.857125Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Model: \"sequential_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_56 (Conv2D)           (None, 640, 640, 32)      11648     \n_________________________________________________________________\nactivation_86 (Activation)   (None, 640, 640, 32)      0         \n_________________________________________________________________\nconv2d_57 (Conv2D)           (None, 640, 640, 64)      100416    \n_________________________________________________________________\nactivation_87 (Activation)   (None, 640, 640, 64)      0         \n_________________________________________________________________\nconv2d_58 (Conv2D)           (None, 640, 640, 128)     204928    \n_________________________________________________________________\nactivation_88 (Activation)   (None, 640, 640, 128)     0         \n_________________________________________________________________\nconv2d_59 (Conv2D)           (None, 640, 640, 32)      36896     \n_________________________________________________________________\nactivation_89 (Activation)   (None, 640, 640, 32)      0         \n_________________________________________________________________\nconv2d_60 (Conv2D)           (None, 640, 640, 16)      4624      \n_________________________________________________________________\nactivation_90 (Activation)   (None, 640, 640, 16)      0         \n_________________________________________________________________\nmax_pooling2d_28 (MaxPooling (None, 320, 320, 16)      0         \n_________________________________________________________________\nbatch_normalization_28 (Batc (None, 320, 320, 16)      64        \n_________________________________________________________________\nflatten_7 (Flatten)          (None, 1638400)           0         \n_________________________________________________________________\nactivation_91 (Activation)   (None, 1638400)           0         \n_________________________________________________________________\ndense_23 (Dense)             (None, 64)                104857664 \n_________________________________________________________________\nactivation_92 (Activation)   (None, 64)                0         \n_________________________________________________________________\ndense_24 (Dense)             (None, 1)                 65        \n_________________________________________________________________\nactivation_93 (Activation)   (None, 1)                 0         \n=================================================================\nTotal params: 105,216,305\nTrainable params: 105,216,273\nNon-trainable params: 32\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"Error: no \"view\" mailcap rules found for type \"image/png\"\n/usr/bin/xdg-open: 869: www-browser: not found\n/usr/bin/xdg-open: 869: links2: not found\n/usr/bin/xdg-open: 869: elinks: not found\n/usr/bin/xdg-open: 869: links: not found\n/usr/bin/xdg-open: 869: lynx: not found\n/usr/bin/xdg-open: 869: w3m: not found\nxdg-open: no method available for opening '/tmp/tmpqcj57mg8.PNG'\n","output_type":"stream"}]},{"cell_type":"code","source":"model = AutoNet.build(numChannels=3, imgRows=640, imgCols=640,numClasses=2)\nopt = keras.optimizers.Adam(learning_rate=0.02)\nmodel.compile(loss=\"binary_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\nmodel.fit(np_train_data, np_train_labels, batch_size=32, epochs=20,verbose=1,validation_data=(np_valid_data, np_valid_labels))","metadata":{"execution":{"iopub.status.busy":"2023-01-06T18:26:49.000081Z","iopub.execute_input":"2023-01-06T18:26:49.000542Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"2023-01-06 18:26:49.049779: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n2023-01-06 18:26:52.629216: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n14/19 [=====================>........] - ETA: 2:47:37 - loss: 43.1838 - accuracy: 0.4732","output_type":"stream"}]},{"cell_type":"code","source":"class estimator:\n    _estimator_type = ''\n    classes_=[]\n    def __init__(self, model, classes):\n        self.model = model\n        self._estimator_type = 'classifier'\n        self.classes_ = classes\n    def predict(self, X):\n        y_prob= self.model.predict(X)\n        y_pred = y_prob.argmax(axis=1)\n    return y_pred\nclass_names=[0,1]\nclassifier = estimator(model, class_names)\n\nplot_confusion_matrix(estimator=classifier, X=np_test_data, y_true=np_test_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate(np_test_data, np_test_labels, verbose=0)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\nmodel.save('AutoNet')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}